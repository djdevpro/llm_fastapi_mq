"""
Exemple: Client OpenAI pointant vers le proxy local.

Usage:
    pip install openai
    python examples/client_openai.py
"""
from openai import OpenAI

# ============================================================
# CONFIGURATION
# ============================================================

client = OpenAI(
    base_url="http://localhost:8007/v1",  # TON PROXY
    api_key="not-needed"  # L'API key est g√©r√©e c√¥t√© serveur
)


# ============================================================
# EXEMPLE 1: Chat simple (non-streaming)
# ============================================================

def chat_simple():
    print("=" * 50)
    print("EXEMPLE 1: Chat simple")
    print("=" * 50)
    
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "Tu es un assistant concis."},
            {"role": "user", "content": "Donne-moi 3 conseils pour bien dormir."}
        ],
        stream=False
    )
    
    print(f"R√©ponse: {response.choices[0].message.content}")
    print(f"Model: {response.model}")
    print(f"ID: {response.id}")
    print()


# ============================================================
# EXEMPLE 2: Chat streaming
# ============================================================

def chat_streaming():
    print("=" * 50)
    print("EXEMPLE 2: Chat streaming")
    print("=" * 50)
    
    stream = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "user", "content": "Raconte-moi une blague courte."}
        ],
        stream=True
    )
    
    print("R√©ponse: ", end="", flush=True)
    for chunk in stream:
        content = chunk.choices[0].delta.content
        if content:
            print(content, end="", flush=True)
    print("\n")


# ============================================================
# EXEMPLE 3: Conversation multi-tours
# ============================================================

def chat_conversation():
    print("=" * 50)
    print("EXEMPLE 3: Conversation multi-tours")
    print("=" * 50)
    
    messages = [
        {"role": "system", "content": "Tu es un prof de maths patient."}
    ]
    
    questions = [
        "C'est quoi une d√©riv√©e ?",
        "Donne-moi un exemple simple.",
        "Et pour x¬≤ ?"
    ]
    
    for q in questions:
        print(f"User: {q}")
        messages.append({"role": "user", "content": q})
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            stream=False
        )
        
        answer = response.choices[0].message.content
        messages.append({"role": "assistant", "content": answer})
        print(f"Assistant: {answer}\n")


# ============================================================
# EXEMPLE 4: JSON Format (response_format)
# ============================================================

def chat_json_format():
    print("=" * 50)
    print("EXEMPLE 4: JSON Format")
    print("=" * 50)
    
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {
                "role": "system", 
                "content": "Tu es un assistant qui r√©pond UNIQUEMENT en JSON valide."
            },
            {
                "role": "user", 
                "content": "Donne-moi 3 films de science-fiction avec leur ann√©e et note sur 10."
            }
        ],
        response_format={"type": "json_object"},
        stream=False
    )
    
    import json
    content = response.choices[0].message.content
    print(f"R√©ponse brute: {content}")
    
    # Parser le JSON
    data = json.loads(content)
    print(f"R√©ponse pars√©e: {json.dumps(data, indent=2, ensure_ascii=False)}")
    print()


# ============================================================
# EXEMPLE 5: JSON Schema (structured outputs)
# ============================================================

def chat_json_schema():
    print("=" * 50)
    print("EXEMPLE 5: JSON Schema (Structured Outputs)")
    print("=" * 50)
    
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "user", "content": "G√©n√®re un utilisateur fictif."}
        ],
        response_format={
            "type": "json_schema",
            "json_schema": {
                "name": "user",
                "strict": True,
                "schema": {
                    "type": "object",
                    "properties": {
                        "nom": {"type": "string"},
                        "age": {"type": "integer"},
                        "email": {"type": "string"},
                        "hobbies": {
                            "type": "array",
                            "items": {"type": "string"}
                        }
                    },
                    "required": ["nom", "age", "email", "hobbies"],
                    "additionalProperties": False
                }
            }
        },
        stream=False
    )
    
    import json
    content = response.choices[0].message.content
    data = json.loads(content)
    
    print(f"Utilisateur g√©n√©r√©:")
    print(f"  Nom: {data['nom']}")
    print(f"  Age: {data['age']}")
    print(f"  Email: {data['email']}")
    print(f"  Hobbies: {', '.join(data['hobbies'])}")
    print()


# ============================================================
# EXEMPLE 6: Liste des mod√®les
# ============================================================

def list_models():
    print("=" * 50)
    print("EXEMPLE 6: Liste des mod√®les")
    print("=" * 50)
    
    models = client.models.list()
    for model in models.data[:10]:  # Limiter √† 10
        print(f"  - {model.id}")
    print("  ...")
    print()


# ============================================================
# MAIN
# ============================================================

if __name__ == "__main__":
    print("\nüöÄ Client OpenAI ‚Üí Proxy local (http://localhost:8007/v1)\n")
    
    # Liste des mod√®les
    #list_models()

    # JSON format
    chat_json_format()
    
    # JSON schema (structured outputs)
    chat_json_schema()
    
    
    print("‚úÖ Termin√©!")
