# ============================================================
# LLM FASTAPI MQ - Configuration
# ============================================================
# Copier ce fichier vers .env et remplir les valeurs

# ============================================================
# OPENAI - REQUIS
# ============================================================
OPENAI_API_KEY=sk-proj-xxxxx

# Optionnel: Organisation et base URL (pour Azure/proxy)
#OPENAI_ORG_ID=org-xxxxx
#OPENAI_BASE_URL=https://your-proxy.com/v1

# Modèle par défaut si non spécifié dans la requête
OPENAI_DEFAULT_MODEL=gpt-4o-mini

# Timeout pour les appels OpenAI (secondes) - 10 min par défaut pour o1/o3
OPENAI_TIMEOUT=600

# ============================================================
# REDIS / BROKER
# ============================================================
REDIS_URL=redis://redis:6379/0

# Optionnel: Broker et backend séparés
#BROKER_URL=redis://redis:6379/0
#RESULT_BACKEND=redis://redis:6379/0

# Pour RabbitMQ (CloudAMQP ou autre)
#BROKER_URL=amqps://user:pass@coral.rmq.cloudamqp.com/vhost

# ============================================================
# CELERY - RATE LIMITING
# ============================================================
# Format: "100/m" (par minute), "10/s" (par seconde), "1000/h" (par heure)
# Appliqué aux tâches chat_completion et batch_embeddings
CELERY_RATE_LIMIT=100/s

# ============================================================
# CELERY - TASK SETTINGS
# ============================================================
# Timeout max par tâche (secondes) - 15 min par défaut pour modèles longs (o1/o3)
CELERY_TASK_TIME_LIMIT=900

# Soft timeout (warning avant kill)
CELERY_TASK_SOFT_TIME_LIMIT=870

# Rétention des résultats (secondes)
CELERY_RESULT_EXPIRES=3600

# Retry automatique
CELERY_MAX_RETRIES=3
CELERY_RETRY_BACKOFF_MAX=60

# ============================================================
# CELERY - WORKER SETTINGS
# ============================================================
# Type de pool:
#   - prefork: multi-process (CPU-bound) - ~150MB par process
#   - threads: multi-thread (I/O-bound) - ~2MB par thread
#   - gevent:  greenlets (scaling massif) - overhead minimal
# Pour les appels LLM (100% I/O), gevent est optimal
CELERY_POOL=threads

# Nombre de tâches en parallèle par worker
# - prefork: 1 par CPU (ex: 4)
# - threads: 10-50 pour I/O (ex: 20)
# - gevent:  100-1000 pour I/O (ex: 100)
CELERY_CONCURRENCY=20

# Prefetch (1 = traitement équitable, >1 = plus rapide mais moins fair)
CELERY_PREFETCH_MULTIPLIER=1

# Queues à écouter (séparées par virgule)
CELERY_QUEUES=high,default,low

# Niveau de log
CELERY_LOGLEVEL=info

# Max mémoire par child process (prefork uniquement, en KB, 0=désactivé)
# Exemple: 204800 = 200MB
CELERY_MAX_MEMORY_PER_CHILD=0

# ============================================================
# API SETTINGS
# ============================================================
# Port de l'API FastAPI
PORT=8007

# Workers Uvicorn
UVICORN_WORKERS=4

# Timeout proxy (secondes) - doit être >= CELERY_TASK_TIME_LIMIT
API_TIMEOUT=900

# ============================================================
# UI CHAT
# ============================================================
UI_PORT=3000
API_URL=http://localhost:8007

# ============================================================
# MONITORING
# ============================================================
# Flower (monitoring Celery)
FLOWER_PORT=5555

# Niveau de log global
LOG_LEVEL=INFO

